# Procesa un archivo de entrada y reconoce tokens
# Input: archivo de texto con código fuente
# Output: lista de tokens o errores léxicos
def tokenize_file(input_file):
    pass

# Identifica tokens en una línea de código
# Input: línea de texto
# Output: lista de tokens o errores léxicos
def tokenize_line(line):
    pass